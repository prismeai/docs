---
title: 'Advanced Topics'
description: 'Explore advanced techniques for leveraging event-driven architecture in AI Builder applications'
---

<Frame>
  <img src="/images/advanced-topics-hero.png" alt="AI Builder Advanced Topics" />
</Frame>

As you become more proficient with AI Builder, understanding and leveraging its event-driven architecture can help you build more sophisticated, powerful, and efficient applications. This guide explores advanced topics focused on event-driven patterns and their practical applications.

## Event-Driven Architecture (EDA)

<Tabs>
  <Tab title="Core Concepts">
    <Frame>
      <img src="/images/event-driven-architecture.png" alt="Event-Driven Architecture Core Concepts" />
    </Frame>
    
    Event-driven architecture is the foundation of AI Builder's flexibility:
    
    - **Events as First-Class Citizens**: All system and user actions generate events
    - **Decoupled Components**: Services communicate through events, not direct calls
    - **Asynchronous Processing**: Actions occur independently of event producers
    - **Scalability**: Components can scale independently based on event load
    - **Extensibility**: New capabilities can subscribe to existing event streams
    
    In Prisme.ai, events flow through the system as messages containing:
    - An event **type** (e.g., `message.created`, `user.login`)
    - A **payload** with event-specific data
    - **Metadata** about the source, timestamp, and routing information
  </Tab>
  
  <Tab title="Key Benefits">
    <Frame>
      <img src="/images/eda-benefits.png" alt="Event-Driven Architecture Benefits" />
    </Frame>
    
    Event-driven architecture provides several advantages:
    
    - **Loose Coupling**: Components can evolve independently
    - **Real-Time Processing**: Events are processed as they occur
    - **Resilience**: Failures in one component don't cascade to others
    - **Auditability**: Complete event history provides audit trail
    - **Flexibility**: Easy to add new event consumers without modifying producers
    
    For AI applications, EDA enables:
    - Seamless integration of multiple AI models and tools
    - Progressive enhancement of features without disruption
    - Detailed tracking of user interactions for personalization
    - Complex workflows that adapt based on AI processing results
  </Tab>
  
  <Tab title="Implementation in Prisme.ai">
    <Frame>
      <img src="/images/prisme-events.png" alt="Events in Prisme.ai" />
    </Frame>
    
    Prisme.ai implements EDA through several mechanisms:
    
    - **System Events**: Generated by the platform for actions like page loads or authentication
    - **User Events**: Triggered by user interactions with blocks
    - **Automation Events**: Created by automation execution
    - **Custom Events**: Defined by developers for application-specific needs
    
    Events can be:
    - **Emitted** by blocks and automations
    - **Listened for** by automations to trigger actions
    - **Queried** for analysis and reporting
    - **Persisted** for auditing and historical analysis
  </Tab>
</Tabs>

## Working with Events

<Steps>
  <Step title="Emitting Events">
    In automations, you can emit events to trigger other processes:
    
    ```yaml
    - emit:
        event: user-action-completed
        payload:
          userId: "{{user.id}}"
          action: "profile-update"
          timestamp: "{{now}}"
    ```
    
    Blocks can also emit events when users interact with them:
    
    ```yaml
    - slug: Action
      text: Update Profile
      type: event
      value: user-update-profile
      payload:
        section: "personal-info"
    ```
    
    These events flow through the system and can trigger other automations or be recorded for analysis.
  </Step>
  
  <Step title="Listening for Events">
    Automations can be triggered by specific events:
    
    ```yaml
    slug: "process-profile-update"
    name: "Process Profile Update"
    when:
      events:
        - user-update-profile
    do:
      - var: payload
        value: "{{event.payload}}"
      - callAPI:
          method: POST
          url: /api/profiles/update
          body: "{{payload}}"
    ```
    
    This creates a chain of actions that can flow through your application, each step triggered by the completion of previous steps.
  </Step>
  
  <Step title="Accessing Event History">
    View event history in several ways:
    
    - **Activity Tab**: See recent events in your workspace
    - **Event Explorer**: Query and filter events for analysis
    - **Elasticsearch/OpenSearch**: Advanced querying for deeper analysis
    
    The complete event stream provides valuable insights into application usage, performance, and user behavior.
  </Step>
  
  <Step title="Analyzing Event Patterns">
    Advanced analytics can reveal important patterns:
    
    - **User Journeys**: Track how users move through your application
    - **Bottlenecks**: Identify where processes slow down
    - **Error Patterns**: Detect recurring issues
    - **Usage Trends**: See how usage evolves over time
    - **Feature Adoption**: Measure which features are most used
    
    These insights drive continuous improvement of your applications.
  </Step>
</Steps>

## Event Sourcing Pattern

<Frame>
  <img src="/images/event-sourcing.png" alt="Event Sourcing Pattern" />
</Frame>

Event sourcing is a powerful pattern where you store state changes as a sequence of events:

<AccordionGroup>
  <Accordion title="Core Principles">
    - **Event Log as Truth**: Events are the primary record of all changes
    - **Immutable History**: Events are never modified, only appended
    - **State Reconstruction**: Current state can be derived by replaying events
    - **Temporal Queries**: Examine system state at any point in time
    - **Complete Audit Trail**: Every change is captured and attributable
    
    This approach provides exceptional data integrity and historical traceability.
  </Accordion>
  
  <Accordion title="Implementation in AI Builder">
    ```javascript
    // Store an event representing a state change
    async function recordStateChange(entityType, entityId, changeType, data) {
      await emit({
        event: `${entityType}.${changeType}`,
        payload: {
          entityId: entityId,
          timestamp: new Date().toISOString(),
          data: data,
          user: getCurrentUser().id
        }
      });
    }
    
    // Reconstruct entity state by replaying events
    async function getEntityState(entityType, entityId) {
      // Retrieve all events for this entity
      const events = await searchEvents({
        type: `${entityType}.*`,
        "payload.entityId": entityId,
        sort: "timestamp:asc"
      });
      
      // Start with empty state
      let state = {};
      
      // Apply each event to evolve the state
      for (const event of events) {
        state = applyEvent(state, event);
      }
      
      return state;
    }
    ```
    
    This pattern is particularly useful for tracking changes to important entities like user profiles, document versions, or configuration settings.
  </Accordion>
  
  <Accordion title="Benefits for AI Applications">
    For AI-powered applications, event sourcing provides several advantages:
    
    - **Training Data Creation**: Captured events become training data for ML models
    - **Decision Transparency**: Every AI decision has a complete audit trail
    - **Behavioral Analysis**: User interactions can be analyzed to improve AI models
    - **Version Comparison**: Changes to AI-generated content can be precisely tracked
    - **Reproducibility**: AI processes can be replayed with historical contexts
  </Accordion>
</AccordionGroup>

## Advanced Event Analytics

<Frame>
  <img src="/images/event-analytics.png" alt="Advanced Event Analytics" />
</Frame>

Every event in your workspace is stored in Elasticsearch/OpenSearch, enabling sophisticated analysis:

<CardGroup cols={2}>
  <Card title="System Mapping" icon="sitemap">
    <p>Create visual maps of your systems based on actual usage:</p>
    <ul>
      <li>Track event flows between components</li>
      <li>Visualize user journeys through your application</li>
      <li>Identify unused features or dead-end paths</li>
      <li>Discover unexpected usage patterns</li>
      <li>Map integration points with external systems</li>
    </ul>
  </Card>
  
  <Card title="Usage Analytics" icon="chart-line">
    <p>Understand how users engage with your applications:</p>
    <ul>
      <li>Measure feature adoption and frequency of use</li>
      <li>Track user session patterns and duration</li>
      <li>Identify popular and underutilized features</li>
      <li>Analyze conversion funnels and drop-off points</li>
      <li>Segment users by behavior patterns</li>
    </ul>
  </Card>
  
  <Card title="Performance Monitoring" icon="gauge-high">
    <p>Track system performance metrics:</p>
    <ul>
      <li>Measure response times for different operations</li>
      <li>Identify bottlenecks in processing flows</li>
      <li>Track API usage and latency</li>
      <li>Monitor automation execution times</li>
      <li>Analyze resource utilization patterns</li>
    </ul>
  </Card>
  
  <Card title="Pattern Discovery" icon="magnifying-glass-chart">
    <p>Find meaningful patterns in your event data:</p>
    <ul>
      <li>Discover common user behavior sequences</li>
      <li>Identify correlations between events</li>
      <li>Detect anomalies that may indicate issues</li>
      <li>Recognize seasonal or time-based patterns</li>
      <li>Find optimization opportunities</li>
    </ul>
  </Card>
</CardGroup>

## Event Mapping for Analytics

<Accordion title="Introduction to Event Mapping">
  As part of Prisme.ai's event-driven architecture, we process events structured with a dynamic identifier `payload`. To ensure consistent and efficient aggregation in both Elasticsearch and OpenSearch, it's essential to explicitly define the mapping for fields used in the payload.
  
  Without proper mapping, you may encounter issues such as:
  - Aggregation inconsistencies between Elasticsearch and OpenSearch
  - Fields interpreted with incorrect data types
  - Performance issues with complex queries
  - Limitations in available analysis capabilities
</Accordion>

<Accordion title="Benefits of Explicit Mapping">
  <CardGroup cols={2}>
    <Card title="Reliability and Consistency" icon="check-double">
      <p>Ensures uniform data treatment:</p>
      <ul>
        <li>Consistent field types across all events</li>
        <li>Prevents errors caused by automatic inference</li>
        <li>Guarantees that aggregations work properly</li>
        <li>Maintains data integrity over time</li>
      </ul>
    </Card>
    
    <Card title="Performance Optimization" icon="bolt">
      <p>Improves query and analysis speed:</p>
      <ul>
        <li>Optimizes indexing for known data structures</li>
        <li>Enables more efficient storage patterns</li>
        <li>Improves complex aggregation performance</li>
        <li>Reduces processing overhead for queries</li>
      </ul>
    </Card>
    
    <Card title="Maintenance and Scalability" icon="arrows-up-down-left-right">
      <p>Simplifies ongoing management:</p>
      <ul>
        <li>Easy-to-read YAML configuration</li>
        <li>Workspace-specific mapping definitions</li>
        <li>Simplified schema evolution</li>
        <li>Better documentation of data structures</li>
      </ul>
    </Card>
    
    <Card title="Cross-Platform Compatibility" icon="globe">
      <p>Works consistently across search engines:</p>
      <ul>
        <li>Identical behavior in Elasticsearch and OpenSearch</li>
        <li>Consistent query results across environments</li>
        <li>Reliable migrations between search technologies</li>
        <li>Future-proof for search engine updates</li>
      </ul>
    </Card>
  </CardGroup>
</Accordion>

<Accordion title="Implementing Event Mapping">
  To implement explicit event mapping, add configuration to your workspace YAML:
  
  ```yaml
  events:
    types:
      usage:
        schema:
          usage:
            type: object
            title: Usage
            properties:
              total_tokens:
                type: number
              completion_tokens:
                type: number
              prompt_tokens:
                type: number
              cost:
                type: number
                format: double
              firstTokenDuration:
                type: number
  ```
  
  <Info>
    This example defines the schema for the `usage` event type, specifying that fields like `total_tokens` and `cost` should be treated as numeric values with specific formats.
  </Info>
  
  When implementing:
  1. Identify the event types requiring explicit mapping
  2. Define their schema with appropriate data types
  3. Add the configuration to your workspace
  4. Test with analytical queries to verify proper behavior
</Accordion>

<Accordion title="Advanced Usage Analytics Example">
  Here's how you might use mapped events for advanced analytics:
  
  ```javascript
  // Query to analyze token usage patterns over time
  const usageAnalytics = await searchEvents({
    type: "usage",
    aggs: {
      usage_over_time: {
        date_histogram: {
          field: "timestamp",
          interval: "day"
        },
        aggs: {
          total_tokens: {
            sum: {
              field: "payload.usage.total_tokens"
            }
          },
          avg_cost: {
            avg: {
              field: "payload.usage.cost"
            }
          },
          models: {
            terms: {
              field: "payload.model"
            }
          }
        }
      }
    }
  });
  
  // Results can be used for visualizations, billing, or optimization
  ```
  
  With proper mapping, these aggregations will be fast and accurate, providing valuable insights into application usage and performance.
</Accordion>

## Practical Event-Driven Patterns

<AccordionGroup>
  <Accordion title="User Activity Tracking">
    <Frame>
      <img src="/images/user-activity-tracking.png" alt="User Activity Tracking" />
    </Frame>
    
    Track and analyze user behavior:
    
    ```yaml
    # Emit events for user actions
    - emit:
        event: user-action
        payload:
          action: page-view
          page: "{{page.slug}}"
          sessionId: "{{session.id}}"
          timestamp: "{{now}}"
    ```
    
    These events can be analyzed to:
    - Create user journey maps
    - Identify popular features
    - Measure engagement
    - Detect unusual behavior
    - Personalize experiences based on usage patterns
  </Accordion>
  
  <Accordion title="AI Model Performance Tracking">
    <Frame>
      <img src="/images/ai-performance-tracking.png" alt="AI Performance Tracking" />
    </Frame>
    
    Monitor and optimize AI model usage:
    
    ```yaml
    # Emit events for AI model usage
    - emit:
        event: model-usage
        payload:
          model: "{{model.name}}"
          prompt_tokens: "{{result.usage.prompt_tokens}}"
          completion_tokens: "{{result.usage.completion_tokens}}"
          total_tokens: "{{result.usage.total_tokens}}"
          duration: "{{result.duration}}"
          cost: "{{result.cost}}"
    ```
    
    This data enables:
    - Cost tracking and optimization
    - Performance benchmarking
    - Model selection refinement
    - Usage pattern analysis
    - Identifying optimization opportunities
  </Accordion>
  
  <Accordion title="Multi-Step Workflows">
    <Frame>
      <img src="/images/multi-step-workflows.png" alt="Multi-Step Workflows" />
    </Frame>
    
    Implement complex business processes through event chains:
    
    ```yaml
    # First automation: Document processing initiated
    - emit:
        event: document-processing-started
        payload:
          documentId: "{{document.id}}"
          stage: "initiated"
          
    # Second automation (triggered by the first event)
    when:
      events:
        - document-processing-started
    do:
      # Process document...
      - emit:
          event: document-processing-completed
          payload:
            documentId: "{{event.payload.documentId}}"
            stage: "processed"
            
    # Third automation (triggered by the second event)
    when:
      events:
        - document-processing-completed
    do:
      # Generate summary...
      - emit:
          event: document-summary-ready
          payload:
            documentId: "{{event.payload.documentId}}"
            stage: "summarized"
    ```
    
    This approach creates modular, maintainable workflows that are:
    - Easily extendable with new steps
    - Resilient to failures (steps can be retried individually)
    - Transparent (full visibility into process state)
    - Analyzable (measure performance of each step)
  </Accordion>
</AccordionGroup>

## Advanced State Management

<CardGroup cols={2}>
  <Card title="Event-Based State" icon="arrows-rotate">
    <p>Derive application state from event streams:</p>
    <ul>
      <li>State as a function of historical events</li>
      <li>Rebuild state by replaying events</li>
      <li>Implement point-in-time recovery</li>
      <li>Support parallel processing of state updates</li>
      <li>Enable audit trail of all state changes</li>
    </ul>
  </Card>
  
  <Card title="Persistent Projections" icon="database">
    <p>Create specialized views of event data:</p>
    <ul>
      <li>Pre-compute common queries for performance</li>
      <li>Generate reports from event streams</li>
      <li>Build dashboards with real-time updates</li>
      <li>Materialize complex aggregate data</li>
      <li>Create denormalized views for specific needs</li>
    </ul>
  </Card>
  
  <Card title="State Synchronization" icon="arrows-to-dot">
    <p>Keep distributed components in sync:</p>
    <ul>
      <li>Propagate state changes as events</li>
      <li>Maintain consistency across components</li>
      <li>Implement eventual consistency patterns</li>
      <li>Handle conflict resolution</li>
      <li>Support offline operation with reconciliation</li>
    </ul>
  </Card>
  
  <Card title="Temporal State" icon="clock">
    <p>Manage state across time dimensions:</p>
    <ul>
      <li>Track state evolution over time</li>
      <li>Implement time-travel debugging</li>
      <li>Support historical queries</li>
      <li>Enable versioned views of data</li>
      <li>Analyze state transition patterns</li>
    </ul>
  </Card>
</CardGroup>

## Next Steps

<CardGroup cols={3}>
  <Card
    title="Performance Optimization"
    icon="gauge-high"
    href="/products/ai-builder/performance"
  >
    Learn techniques for optimizing event processing
  </Card>
  <Card
    title="Analytics Dashboards"
    icon="chart-line"
    href="/products/ai-builder/analytics"
  >
    Build insights dashboards using event data
  </Card>
  <Card
    title="Advanced Event Patterns"
    icon="sitemap"
    href="/products/ai-builder/event-patterns"
  >
    Explore more sophisticated event-driven architectures
  </Card>
</CardGroup>