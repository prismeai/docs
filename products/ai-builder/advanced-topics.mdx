---
title: 'Advanced Topics'
description: 'Explore advanced techniques for leveraging event-driven architecture in AI Builder applications'
---

<Frame>
  <img src="/images/advanced-topics-hero.png" alt="AI Builder Advanced Topics" />
</Frame>

As you become more proficient with AI Builder, understanding and leveraging its event-driven architecture can help you build more sophisticated, powerful, and efficient applications. This guide explores advanced topics focused on event-driven patterns and their practical applications.

## Event-Driven Architecture (EDA)

<Tabs>
  <Tab title="Core Concepts">
    <Frame>
      <img src="/images/event-driven-architecture.png" alt="Event-Driven Architecture Core Concepts" />
    </Frame>
    
    Event-driven architecture is the foundation of AI Builder's flexibility:
    
    - **Events as First-Class Citizens**: All system and user actions generate events
    - **Decoupled Components**: Services communicate through events, not direct calls
    - **Asynchronous Processing**: Actions occur independently of event producers
    - **Scalability**: Components can scale independently based on event load
    - **Extensibility**: New capabilities can subscribe to existing event streams
    
    In Prisme.ai, events flow through the system as messages containing:
    - An event **type** (e.g., `message.created`, `user.login`)
    - A **payload** with event-specific data
    - **Metadata** about the source, timestamp, and routing information
  </Tab>
  
  <Tab title="Key Benefits">
    <Frame>
      <img src="/images/eda-benefits.png" alt="Event-Driven Architecture Benefits" />
    </Frame>
    
    Event-driven architecture provides several advantages:
    
    - **Loose Coupling**: Components can evolve independently
    - **Real-Time Processing**: Events are processed as they occur
    - **Resilience**: Failures in one component don't cascade to others
    - **Auditability**: Complete event history provides audit trail
    - **Flexibility**: Easy to add new event consumers without modifying producers
    
    For AI applications, EDA enables:
    - Seamless integration of multiple AI models and tools
    - Progressive enhancement of features without disruption
    - Detailed tracking of user interactions for personalization
    - Complex workflows that adapt based on AI processing results
  </Tab>
  
  <Tab title="Implementation in Prisme.ai">
    <Frame>
      <img src="/images/prisme-events.png" alt="Events in Prisme.ai" />
    </Frame>
    
    Prisme.ai implements EDA through several mechanisms:
    
    - **System Events**: Generated by the platform for actions like page loads or authentication
    - **User Events**: Triggered by user interactions with blocks
    - **Automation Events**: Created by automation execution
    - **Custom Events**: Defined by developers for application-specific needs
    
    Events can be:
    - **Emitted** by blocks and automations
    - **Listened for** by automations to trigger actions
    - **Queried** for analysis and reporting
    - **Persisted** for auditing and historical analysis
  </Tab>
</Tabs>

## Working with Events

<Steps>
  <Step title="Emitting Events">
    In automations, you can emit events to trigger other processes:
    
    ```yaml
    - emit:
        event: user-action-completed
        payload:
          userId: "{{user.id}}"
          action: "profile-update"
          timestamp: "{{now}}"
    ```
    
    Blocks can also emit events when users interact with them:
    
    ```yaml
    - slug: Action
      text: Update Profile
      type: event
      value: user-update-profile
      payload:
        section: "personal-info"
    ```
    
    These events flow through the system and can trigger other automations or be recorded for analysis.
  </Step>
  
  <Step title="Listening for Events">
    Automations can be triggered by specific events:
    
    ```yaml
    slug: "process-profile-update"
    name: "Process Profile Update"
    when:
      events:
        - user-update-profile
    do:
      - set: payload
        value: "{{event.payload}}"
      - callAPI:
          method: POST
          url: /api/profiles/update
          body: "{{payload}}"
    ```
    
    This creates a chain of actions that can flow through your application, each step triggered by the completion of previous steps.
  </Step>
  
  <Step title="Accessing Event History">
    View event history in several ways:
    
    - **Activity Tab**: See recent events in your workspace
    - **Event Explorer**: Query and filter events for analysis
    - **Elasticsearch/OpenSearch**: Advanced querying for deeper analysis
    
    The complete event stream provides valuable insights into application usage, performance, and user behavior.
  </Step>
  
  <Step title="Analyzing Event Patterns">
    Advanced analytics can reveal important patterns:
    
    - **User Journeys**: Track how users move through your application
    - **Bottlenecks**: Identify where processes slow down
    - **Error Patterns**: Detect recurring issues
    - **Usage Trends**: See how usage evolves over time
    - **Feature Adoption**: Measure which features are most used
    
    These insights drive continuous improvement of your applications.
  </Step>
</Steps>

## Advanced Event Analytics

<Frame>
  <img src="/images/event-analytics.png" alt="Advanced Event Analytics" />
</Frame>

Every event in your workspace is stored in Elasticsearch/OpenSearch, enabling custom analysis:

<CardGroup cols={2}>
  <Card title="System Mapping" icon="sitemap">
    <p>Create visual maps of your systems based on actual usage:</p>
    <ul>
      <li>Track event flows between components</li>
      <li>Visualize user journeys through your application</li>
      <li>Identify unused features or dead-end paths</li>
      <li>Discover unexpected usage patterns</li>
      <li>Map integration points with external systems</li>
    </ul>
  </Card>
  
  <Card title="Usage Analytics" icon="chart-line">
    <p>Understand how users engage with your applications:</p>
    <ul>
      <li>Measure feature adoption and frequency of use</li>
      <li>Track user session patterns and duration</li>
      <li>Identify popular and underutilized features</li>
      <li>Analyze conversion funnels and drop-off points</li>
      <li>Segment users by behavior patterns</li>
    </ul>
  </Card>
  
  <Card title="Performance Monitoring" icon="gauge-high">
    <p>Track system performance metrics:</p>
    <ul>
      <li>Measure response times for different operations</li>
      <li>Identify bottlenecks in processing flows</li>
      <li>Track API usage and latency</li>
      <li>Monitor automation execution times</li>
      <li>Analyze resource utilization patterns</li>
    </ul>
  </Card>
  
  <Card title="Pattern Discovery" icon="magnifying-glass-chart">
    <p>Find meaningful patterns in your event data:</p>
    <ul>
      <li>Discover common user behavior sequences</li>
      <li>Identify correlations between events</li>
      <li>Detect anomalies that may indicate issues</li>
      <li>Recognize seasonal or time-based patterns</li>
      <li>Find optimization opportunities</li>
    </ul>
  </Card>
</CardGroup>

## Event Mapping for Analytics

<Accordion title="Introduction to Event Mapping">
  As part of Prisme.ai's event-driven architecture, we process events structured with a dynamic identifier `payload`. To ensure consistent and efficient aggregation in both Elasticsearch and OpenSearch, it's essential to explicitly define the mapping for fields used in the payload.
  
  Without proper mapping, you may encounter issues such as:
  - Aggregation inconsistencies between Elasticsearch and OpenSearch
  - Fields interpreted with incorrect data types
  - Performance issues with complex queries
  - Limitations in available analysis capabilities
</Accordion>

<Accordion title="Benefits of Explicit Mapping">
  <CardGroup cols={2}>
    <Card title="Reliability and Consistency" icon="check-double">
      <p>Ensures uniform data treatment:</p>
      <ul>
        <li>Consistent field types across all events</li>
        <li>Prevents errors caused by automatic inference</li>
        <li>Guarantees that aggregations work properly</li>
        <li>Maintains data integrity over time</li>
      </ul>
    </Card>
    
    <Card title="Performance Optimization" icon="bolt">
      <p>Improves query and analysis speed:</p>
      <ul>
        <li>Optimizes indexing for known data structures</li>
        <li>Enables more efficient storage patterns</li>
        <li>Improves complex aggregation performance</li>
        <li>Reduces processing overhead for queries</li>
      </ul>
    </Card>
    
    <Card title="Maintenance and Scalability" icon="arrows-up-down-left-right">
      <p>Simplifies ongoing management:</p>
      <ul>
        <li>Easy-to-read YAML configuration</li>
        <li>Workspace-specific mapping definitions</li>
        <li>Simplified schema evolution</li>
        <li>Better documentation of data structures</li>
      </ul>
    </Card>
    
    <Card title="Cross-Platform Compatibility" icon="globe">
      <p>Works consistently across search engines:</p>
      <ul>
        <li>Identical behavior in Elasticsearch and OpenSearch</li>
        <li>Consistent query results across environments</li>
        <li>Reliable migrations between search technologies</li>
        <li>Future-proof for search engine updates</li>
      </ul>
    </Card>
  </CardGroup>
</Accordion>

<Accordion title="Implementing Event Mapping">
  To implement explicit event mapping, add configuration to your workspace YAML:
  
  ```yaml
  events:
    types:
      usage:
        schema:
          usage:
            type: object
            title: Usage
            properties:
              total_tokens:
                type: number
              completion_tokens:
                type: number
              prompt_tokens:
                type: number
              cost:
                type: number
                format: double
              firstTokenDuration:
                type: number
  ```
  
  <Info>
    This example defines the schema for the `usage` event type, specifying that fields like `total_tokens` and `cost` should be treated as numeric values with specific formats.
  </Info>
  
  When implementing:
  1. Identify the event types requiring explicit mapping
  2. Define their schema with appropriate data types
  3. Add the configuration to your workspace
  4. Test with analytical queries to verify proper behavior
</Accordion>

<Accordion title="Advanced Usage Analytics Example">
  Here's how you might use mapped events for advanced analytics:
  
  ```javascript
  // Query to analyze token usage patterns over time
  const usageAnalytics = await searchEvents({
    type: "usage",
    aggs: {
      usage_over_time: {
        date_histogram: {
          field: "timestamp",
          interval: "day"
        },
        aggs: {
          total_tokens: {
            sum: {
              field: "payload.usage.total_tokens"
            }
          },
          avg_cost: {
            avg: {
              field: "payload.usage.cost"
            }
          },
          models: {
            terms: {
              field: "payload.model"
            }
          }
        }
      }
    }
  });
  
  // Results can be used for visualizations, billing, or optimization
  ```
  
  With proper mapping, these aggregations will be fast and accurate, providing valuable insights into application usage and performance.
</Accordion>

## Practical Event-Driven Patterns

<AccordionGroup>
  <Accordion title="User Activity Tracking">
    <Frame>
      <img src="/images/user-activity-tracking.png" alt="User Activity Tracking" />
    </Frame>
    
    Track and analyze user behavior:
    
    ```yaml
    # Emit events for user actions
    - emit:
        event: user-action
        payload:
          action: page-view
          page: "{{page.slug}}"
          sessionId: "{{session.id}}"
          timestamp: "{{now}}"
    ```
    
    These events can be analyzed to:
    - Create user journey maps
    - Identify popular features
    - Measure engagement
    - Detect unusual behavior
    - Personalize experiences based on usage patterns
  </Accordion>
  
  <Accordion title="AI Model Performance Tracking">
    <Frame>
      <img src="/images/ai-performance-tracking.png" alt="AI Performance Tracking" />
    </Frame>
    
    Monitor and optimize AI model usage:
    
    ```yaml
    # Emit events for AI model usage
    - emit:
        event: model-usage
        payload:
          model: "{{model.name}}"
          prompt_tokens: "{{result.usage.prompt_tokens}}"
          completion_tokens: "{{result.usage.completion_tokens}}"
          total_tokens: "{{result.usage.total_tokens}}"
          duration: "{{result.duration}}"
          cost: "{{result.cost}}"
    ```
    
    This data enables:
    - Cost tracking and optimization
    - Performance benchmarking
    - Model selection refinement
    - Usage pattern analysis
    - Identifying optimization opportunities
  </Accordion>
  
  <Accordion title="Multi-Step Workflows">
    <Frame>
      <img src="/images/multi-step-workflows.png" alt="Multi-Step Workflows" />
    </Frame>
    
    Implement complex business processes through event chains:
    
    ```yaml
    # First automation: Document processing initiated
    - emit:
        event: document-processing-started
        payload:
          documentId: "{{document.id}}"
          stage: "initiated"
          
    # Second automation (triggered by the first event)
    when:
      events:
        - document-processing-started
    do:
      # Process document...
      - emit:
          event: document-processing-completed
          payload:
            documentId: "{{event.payload.documentId}}"
            stage: "processed"
            
    # Third automation (triggered by the second event)
    when:
      events:
        - document-processing-completed
    do:
      # Generate summary...
      - emit:
          event: document-summary-ready
          payload:
            documentId: "{{event.payload.documentId}}"
            stage: "summarized"
    ```
    
    This approach creates modular, maintainable workflows that are:
    - Easily extendable with new steps
    - Resilient to failures (steps can be retried individually)
    - Transparent (full visibility into process state)
    - Analyzable (measure performance of each step)
  </Accordion>
</AccordionGroup>