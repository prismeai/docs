---
title: 'Custom Code'
description: 'Execute custom JavaScript and Python code within your Prisme.ai workflows'
---

<Frame>
  <img src="/images/custom-code.png" alt="Custom Code" />
</Frame>


The Custom Code app is a powerful infrastructure component in the Prisme.ai ecosystem that allows you to execute custom logic within your automations and workflows. It provides a secure, managed environment for running JavaScript and Python code, enabling complex data transformations, integrations, and calculations that go beyond what's possible with standard automation steps.

## Overview

Custom Code serves as a flexible extension point for your Prisme.ai solutions:

<CardGroup cols={2}>
  <Card title="Code Execution" icon="code">
    Run custom JavaScript and Python code in a secure environment
  </Card>
  <Card title="Data Transformation" icon="arrows-rotate">
    Transform data with complex logic and algorithms
  </Card>
  <Card title="Integration Bridge" icon="bridge">
    Connect to systems without pre-built integrations
  </Card>
  <Card title="Advanced Processing" icon="microchip">
    Implement sophisticated data processing and analytics
  </Card>
</CardGroup>

This infrastructure app is particularly valuable for handling unique business logic, specialized calculations, and custom data processing requirements.

## Key Features

<Tabs>
  <Tab title="Code Execution Environment">
    A secure, controlled environment for running code:
    
    - **JavaScript Runtime**: Execute JavaScript/TypeScript
    - **Python Runtime**: Run Python 3.x code
    - **Isolation**: Code runs in a containerized environment
    - **Resource Limits**: CPU, memory, and execution time controls
    - **Version Management**: Control runtime versions
    
    This execution environment balances flexibility with security and stability.
  </Tab>
  
  <Tab title="Function Management">
    Organize and manage custom functions:
    
    - **Function Library**: Central repository of reusable functions
    - **Version Control**: Track changes to functions over time
    - **Parameter Definition**: Define and validate input parameters
    - **Default Values**: Set fallback values for optional parameters
    - **Documentation**: Document function purpose and usage
    
    These management features promote code reuse and maintainability.
  </Tab>
  
  <Tab title="Integration Capabilities">
    Connect code with the broader Prisme.ai ecosystem:
    
    - **Workflow Integration**: Call functions from automations
    - **Data Passing**: Exchange data between functions and workflows
    - **Context Access**: Access runtime context information
    - **Error Handling**: Robust error management
    - **Logging**: Capture execution details for monitoring
    
    These integration capabilities create a seamless experience within your workflows.
  </Tab>
  
  <Tab title="Development Tools">
    Tools to support code development and testing:
    
    - **Code Editor**: Syntax highlighting and assistance
    - **Testing Framework**: Validate function behavior
    - **Debugging Tools**: Identify and resolve issues
    - **Execution History**: Review past runs and outputs
    - **Performance Metrics**: Monitor execution efficiency
    
    These development tools improve productivity and code quality.
  </Tab>
</Tabs>

## How Custom Code Works

Custom Code functions are defined, managed, and executed through a structured process:

<Steps>
  <Step title="Function Definition">
    Create a function with code, parameters, and metadata:
    - Write the function code
    - Define input parameters with types and validation
    - Specify output format
    - Add documentation
  </Step>
  <Step title="Storage and Management">
    Store functions in the Custom Code repository:
    - Save to the function library
    - Version and track changes
    - Organize by category or purpose
    - Control access permissions
  </Step>
  <Step title="Execution from Workflows">
    Call functions from automations:
    - Reference the function by name
    - Provide required parameters
    - Map workflow data to parameters
    - Capture the function output
  </Step>
  <Step title="Runtime Execution">
    Execute the function in a secure environment:
    - Validate input parameters
    - Run the code in an isolated container
    - Monitor execution and resource usage
    - Handle errors and exceptions
  </Step>
  <Step title="Result Processing">
    Return the result to the calling workflow:
    - Format the output according to specifications
    - Pass the result back to the workflow
    - Log execution details
    - Track performance metrics
  </Step>
</Steps>

This process provides a controlled yet flexible way to include custom logic in your automations.

## JavaScript Functions

JavaScript functions in Custom Code allow you to implement a wide range of data processing and transformation tasks:

<AccordionGroup>
  <Accordion title="Function Structure">
    The basic structure of a JavaScript function:
    
    ```javascript
    // Function to transform data
    function processData(data) {
      // Data processing logic
      const result = data.map(item => {
        return {
          id: item.id,
          name: item.name.toUpperCase(),
          value: item.amount * 1.1
        };
      });
      
      return result;
    }
    
    // Export the function result
    return processData(data);
    ```
    
    This function takes a data parameter, transforms it, and returns the result.
  </Accordion>
  
  <Accordion title="Parameter Configuration">
    Configure function parameters for validation and documentation:
    
    ```yaml
    functions:
      processData:
        code: |
          // Function code here
        parameters:
          data:
            type: array
            description: Array of items to process
            default: []
    ```
    
    This configuration defines a `data` parameter of type `array` with a description and default value.
  </Accordion>
  
  <Accordion title="Advanced Example">
    A more sophisticated JavaScript function:
    
    ```javascript
    // Function to classify text
    function classifyText(text, categories) {
      // Simple classification logic
      const lowerText = text.toLowerCase();
      
      // Check each category for matches
      for (const category of categories) {
        for (const keyword of category.keywords) {
          if (lowerText.includes(keyword.toLowerCase())) {
            return {
              category: category.name,
              confidence: 0.8,
              keyword: keyword
            };
          }
        }
      }
      
      // Default classification
      return {
        category: 'unclassified',
        confidence: 0.5,
        keyword: null
      };
    }
    
    // Export the function result
    return classifyText(text, categories);
    ```
    
    This function classifies text based on keyword matching against categories.
  </Accordion>
  
  <Accordion title="Available Libraries">
    JavaScript functions have access to  built-in libraries whitelisted by your orgnization registry.
    
    These libraries help you accomplish common tasks without reinventing the wheel.
    
    ```javascript
    // Example using libraries
    const _ = require('lodash');
    const moment = require('moment');
    const axios = require('axios');
    
    async function processData(data) {
      // Group data by date
      const grouped = _.groupBy(data, item => 
        moment(item.timestamp).format('YYYY-MM-DD')
      );
      
      // Enrich with external data
      for (const date in grouped) {
        try {
          const response = await axios.get(`https://api.example.com/data/${date}`);
          grouped[date].externalData = response.data;
        } catch (error) {
          console.error(`Error fetching data for ${date}:`, error.message);
        }
      }
      
      return grouped;
    }
    
    // Export the function result
    return processData(data);
    ```
  </Accordion>
</AccordionGroup>

## Python Functions

Python functions in Custom Code provide access to Python's rich ecosystem for data analysis, machine learning, and scientific computing:

<AccordionGroup>
  <Accordion title="Function Structure">
    The basic structure of a Python function:
    
    ```python
    # Function to analyze numeric data
    def analyze_data(data):
        # Data analysis logic
        result = {
            'count': len(data),
            'sum': sum(data),
            'average': sum(data) / len(data) if data else 0,
            'min': min(data) if data else None,
            'max': max(data) if data else None
        }
        
        return result
    
    # Execute the function and return result
    result = analyze_data(data)
    ```
    
    This function takes a list of numeric values and returns basic statistical measures.
  </Accordion>
  
  <Accordion title="Parameter Configuration">
    Configure Python function parameters:
    
    ```yaml
    functions:
      analyze_data:
        code: |
          # Python code here
        parameters:
          data:
            type: array
            description: Array of numeric values to analyze
            default: []
    ```
    
    This configuration is similar to JavaScript function parameters, providing type information, description, and default values.
  </Accordion>
  
  <Accordion title="Advanced Example">
    A more sophisticated Python function:
    
    ```python
    import pandas as pd
    from sklearn.cluster import KMeans
    import numpy as np
    
    def cluster_data(data, num_clusters=3):
        # Convert to DataFrame if not already
        if not isinstance(data, pd.DataFrame):
            df = pd.DataFrame(data)
        else:
            df = data
            
        # Select numeric columns
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        features = df[numeric_cols].fillna(0)
        
        # Perform clustering
        kmeans = KMeans(n_clusters=num_clusters, random_state=42)
        df['cluster'] = kmeans.fit_predict(features)
        
        # Compute cluster statistics
        cluster_stats = df.groupby('cluster').agg({
            col: ['mean', 'min', 'max', 'count'] for col in numeric_cols
        })
        
        return {
            'clustered_data': df.to_dict(orient='records'),
            'cluster_centers': kmeans.cluster_centers_.tolist(),
            'cluster_stats': cluster_stats.to_dict()
        }
    
    # Execute and return result
    result = cluster_data(data, num_clusters)
    ```
    
    This function performs K-means clustering on numeric data and returns the clustered data, cluster centers, and statistics.
  </Accordion>
  
  <Accordion title="Available Libraries">
    Python functions have access to popular data science and utility libraries whitelisted by your DevSecOps Teams.
    
    These libraries enable sophisticated data analysis and machine learning within your workflows.
    
    ```python
    import pandas as pd
    import numpy as np
    from nltk.sentiment import SentimentIntensityAnalyzer
    import requests
    
    def analyze_sentiment(texts):
        # Initialize sentiment analyzer
        sia = SentimentIntensityAnalyzer()
        
        # Analyze each text
        results = []
        for text in texts:
            sentiment = sia.polarity_scores(text)
            results.append({
                'text': text,
                'sentiment': sentiment,
                'classification': 'positive' if sentiment['compound'] > 0.05 
                                  else 'negative' if sentiment['compound'] < -0.05 
                                  else 'neutral'
            })
            
        # Get overall statistics
        df = pd.DataFrame(results)
        stats = {
            'positive_count': sum(df['classification'] == 'positive'),
            'negative_count': sum(df['classification'] == 'negative'),
            'neutral_count': sum(df['classification'] == 'neutral'),
            'average_compound': np.mean(df['sentiment'].apply(lambda x: x['compound']))
        }
        
        return {
            'detailed_results': results,
            'statistics': stats
        }
    
    # Execute the function
    result = analyze_sentiment(texts)
    ```
  </Accordion>
</AccordionGroup>

## Integration with Prisme.ai Workflows

Custom Code is designed to integrate seamlessly with Prisme.ai automations:

<Steps>
  <Step title="Calling Functions from Automations">
    Reference Custom Code functions in your automation YAML:
    
    ```yaml
    slug: process-data-workflow
    name: Process Data Workflow
    do:
      - Custom Code.run function:
          function: processData
          parameters:
            data: '{{payload.items}}'
          output: processedData
      - emit:
          event: data-processed
          payload:
            result: '{{processedData}}'
    ```
    
    This automation calls the `processData` function with input from the payload and emits the result as an event.
  </Step>
  <Step title="Handling Function Results">
    Process the output from Custom Code functions:
    
    ```yaml
    - conditions:
        '{{processedData.success}}':
          - Collection.insert:
              data: '{{processedData.items}}'
        default:
          - emit:
              event: processing-error
              payload:
                error: '{{processedData.error}}'
    ```
    
    This example shows conditional logic based on the function's output.
  </Step>
  <Step title="Error Handling">
    Implement robust error handling for Custom Code execution:
    
    ```yaml
    - Custom Code.run function:
        function: riskAnalysis
        parameters:
          data: '{{payload.clientData}}'
        output: riskResult
    - conditions:
        '{{riskResult.error}}':
          - set:
              name: errorDetails
              value:
                message: "Error in risk analysis"
                details: '{{riskResult.error}}'
                timestamp: '{% now() %}'
          - Collection.insert:
              data: '{{errorDetails}}'
              collection: errors
          - break: {}
        default: []
    ```
    
    This approach captures and logs errors from function execution.
  </Step>
</Steps>

## Common Use Cases

Custom Code enables a wide range of use cases:

<CardGroup cols={2}>
  <Card title="Data Transformation" icon="arrows-rotate">
    Implement complex data transformations:
    - Format conversion
    - Schema mapping
    - Data normalization
    - Content extraction
  </Card>
  <Card title="Advanced Analysis" icon="chart-line">
    Perform sophisticated data analysis:
    - Statistical calculations
    - Pattern recognition
    - Trend identification
    - Risk assessment
  </Card>
  <Card title="Integration Logic" icon="plug">
    Create custom integration components:
    - API request formatting
    - Response processing
    - Protocol implementations
    - Legacy system connections
  </Card>
  <Card title="Business Logic" icon="building">
    Implement specialized business rules:
    - Pricing calculations
    - Eligibility determinations
    - Approval workflows
    - Validation logic
  </Card>
</CardGroup>

## Example: Data Classification

A common use case for Custom Code is classifying data based on content. Here's an example that classifies documents:

```javascript
// Function to classify documents
function classifyDocument(document) {
  // Extract text content
  const text = document.content.toLowerCase();
  
  // Define classification patterns
  const classifications = [
    {
      category: "invoice",
      patterns: ["invoice", "bill to", "payment due", "invoice number", "total amount"]
    },
    {
      category: "contract",
      patterns: ["agreement", "terms and conditions", "parties", "hereby agree", "signature"]
    },
    {
      category: "resume",
      patterns: ["experience", "education", "skills", "employment", "qualification"]
    },
    {
      category: "report",
      patterns: ["analysis", "findings", "conclusion", "summary", "recommendations"]
    }
  ];
  
  // Score each category
  const scores = classifications.map(classification => {
    let score = 0;
    
    // Count pattern matches
    for (const pattern of classification.patterns) {
      if (text.includes(pattern)) {
        score += 1;
      }
    }
    
    return {
      category: classification.category,
      score: score / classification.patterns.length
    };
  });
  
  // Find the highest scoring category
  const bestMatch = scores.reduce((best, current) => 
    current.score > best.score ? current : best, 
    { category: "other", score: 0 }
  );
  
  // Only classify if score is above threshold
  if (bestMatch.score >= 0.3) {
    return {
      category: bestMatch.category,
      confidence: bestMatch.score,
      document_id: document.id
    };
  } else {
    return {
      category: "unknown",
      confidence: 0,
      document_id: document.id
    };
  }
}

// Execute the function and return result
return classifyDocument(document);
```

This function analyzes document content, scoring it against different category patterns, and assigns the most likely classification if it meets a minimum confidence threshold.

## Example: Advanced Data Analysis with Python

When you need sophisticated data analysis, Python's ecosystem provides powerful capabilities:

```python
import pandas as pd
import numpy as np
from sklearn.ensemble import IsolationForest

def detect_anomalies(transactions):
    # Convert to DataFrame
    df = pd.DataFrame(transactions)
    
    # Select numeric features
    features = df[['amount', 'transaction_count', 'average_value']]
    
    # Fit isolation forest model
    model = IsolationForest(contamination=0.05, random_state=42)
    df['anomaly'] = model.fit_predict(features)
    
    # Anomaly is -1, normal is 1, convert to boolean
    df['is_anomaly'] = df['anomaly'] == -1
    
    # Calculate anomaly score (higher means more anomalous)
    df['anomaly_score'] = model.score_samples(features)
    df['anomaly_score'] = 1 - (df['anomaly_score'] - df['anomaly_score'].min()) / (df['anomaly_score'].max() - df['anomaly_score'].min())
    
    # Identify anomalous transactions
    anomalies = df[df['is_anomaly']].sort_values('anomaly_score', ascending=False)
    
    # Prepare results
    result = {
        'anomaly_count': len(anomalies),
        'anomaly_percentage': (len(anomalies) / len(df)) * 100,
        'anomalies': anomalies.to_dict(orient='records'),
        'anomaly_statistics': {
            'amount': {
                'mean': anomalies['amount'].mean(),
                'min': anomalies['amount'].min(),
                'max': anomalies['amount'].max()
            },
            'transaction_count': {
                'mean': anomalies['transaction_count'].mean(),
                'min': anomalies['transaction_count'].min(),
                'max': anomalies['transaction_count'].max()
            }
        }
    }
    
    return result

# Execute the function
result = detect_anomalies(transactions)
```

This Python function uses the Isolation Forest algorithm to detect anomalous transactions based on multiple features, providing detailed information about the detected anomalies.

## Best Practices

Follow these recommendations to get the most from Custom Code:

<AccordionGroup>
  <Accordion title="Code Quality">
    Maintain high standards of code quality:
    
    - Write clean, readable code with proper indentation
    - Include comments to explain complex logic
    - Use meaningful variable and function names
    - Break complex functions into smaller, focused ones
    - Add error handling for robustness
    - Validate inputs and handle edge cases
    
    Quality code is easier to maintain and less prone to errors.
  </Accordion>
  
  <Accordion title="Performance Optimization">
    Optimize code for efficient execution:
    
    - Minimize external API calls
    - Use efficient data structures and algorithms
    - Avoid unnecessary loops and iterations
    - Process only the data you need
    - Use built-in functions and libraries when available
    - Consider the impact of large datasets
    
    Efficient code runs faster and uses fewer resources.
  </Accordion>
  
  <Accordion title="Security Considerations">
    Implement secure coding practices:
    
    - Validate and sanitize all inputs
    - Avoid hardcoded credentials
    - Use platform security features
    - Be cautious with external libraries
    - Implement proper error handling
    - Follow the principle of least privilege
    
    Security should be a fundamental consideration in all custom code.
  </Accordion>
  
  <Accordion title="Testing and Debugging">
    Thoroughly test your functions:
    
    - Test with various input scenarios
    - Check edge cases (empty data, large data, etc.)
    - Verify error handling
    - Use logging for debugging
    - Validate outputs against expected results
    - Update tests when functions change
    
    Comprehensive testing ensures reliability and correctness.
  </Accordion>
</AccordionGroup>

## Limitations and Considerations

When using Custom Code, be aware of these considerations:

- **Execution Environment**: Code runs in a controlled environment with resource limits. Very compute-intensive operations may not be suitable.

- **External Access**: For security reasons, network access is restricted. External API calls and file system access follow platform security policies.

- **Runtime Duration**: Functions have maximum execution times. Long-running operations should be designed with this in mind.

- **Library Availability**: While many common libraries are available, some specialized packages may not be pre-installed. Check documentation for the current list.

- **State Management**: Functions are stateless by default. Persistent state should be stored using platform services like Collection.

## Integration with Other Prisme.ai Products

Custom Code works seamlessly with other Prisme.ai products:

<Tabs>
  <Tab title="AI Knowledge">
    Enhance AI Knowledge with custom processing:
    
    - Pre-process documents before ingestion
    - Create custom embedding algorithms
    - Implement specialized reranking logic
    - Generate synthetic training data
    - Analyze query patterns and performance
    
    This integration improves retrieval accuracy and knowledge base utility.
  </Tab>
  
  <Tab title="AI Builder">
    Extend automation capabilities with custom logic:
    
    - Implement complex workflow decisions
    - Create custom integration points
    - Build specialized data transformations
    - Generate dynamic content
    - Process and analyze event data
    
    This combination enables sophisticated automation scenarios.
  </Tab>
  
  <Tab title="Crawler">
    Enhance web content extraction with custom processing:
    
    - Implement specialized content extraction
    - Clean and normalize crawled data
    - Filter and categorize content
    - Extract structured data from HTML
    - Transform content into specific formats
    
    This integration improves the quality and usability of extracted web content.
  </Tab>
  
  <Tab title="Collection">
    Add sophisticated data operations for Collection:
    
    - Implement custom querying logic
    - Create specialized aggregations
    - Build data migration tools
    - Generate data quality reports
    - Perform batch processing operations
    
    This combination enhances data management capabilities.
  </Tab>
</Tabs>

## Next Steps

<CardGroup cols={2}>
  <Card title="API Integrations" icon="plug" href="/apps-store/marketplace/api">
    Learn about connecting to external APIs
  </Card>
  <Card title="Crawler" icon="spider" href="/apps-store/marketplace/crawler">
    Discover web content extraction capabilities
  </Card>
  <Card title="Collection" icon="database" href="/apps-store/marketplace/collection">
    Manage data with simplified database access
  </Card>
  <Card title="Extending Apps" icon="puzzle-piece" href="/apps-store/marketplace/extending-apps">
    Create your own custom integrations
  </Card>
</CardGroup>