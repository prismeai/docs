---
title: "AI Knowledge"
description: "Learn how to use AI Knowledge — Prisme.ai’s RAG-based product for creating, managing, and evaluating enterprise knowledge agents."
---

AI Knowledge is Prisme.ai’s **Retrieval-Augmented Generation (RAG)** product designed to transform your organization’s documents, APIs, and structured information into intelligent, queryable agents.

It allows enterprises to **upload, organize, and evaluate** knowledge sources within a secure workspace, connecting them directly to conversational agents, analytics dashboards, or automated workflows.

---

## Business Context

In large organizations, information is fragmented across multiple systems, formats, and teams.\
AI Knowledge consolidates these data silos into a unified knowledge base that powers enterprise-grade AI assistants — while preserving **data sovereignty, compliance, and performance visibility**.

It empowers teams to:

- Centralize and govern internal documentation.
- Enable contextual responses grounded in trusted enterprise sources.
- Continuously evaluate and improve AI accuracy through structured testing.

---

## Key Capabilities

<Columns cols={2}>
  <Card>
    Upload, process, and index**enterprise documents**  (PDFs, Word, PowerPoint, or HTML) with automatic extraction, embeddings, and versioning.
  </Card>
  <Card>
    Configure **RAG parameters** such as chunk size, overlap, and embedding models to optimize retrieval precision and recall.
  </Card>
</Columns>

<Columns cols={2}>
  <Card>
    Connect multiple users and administrators to the same knowledge workspace with **role-based access control**.
  </Card>
  <Card>
    Evaluate knowledge quality and **AI performance** using built-in testing, scoring, and feedback metrics for human-in-the-loop evaluation.
  </Card>
</Columns>

<Columns cols={2}>
  <Card>
    Enable native tools and features such as **Image Generation**, **Web Browsing**, **Deep Research**, and the **Code Interpreter**.
  </Card>
  <Card>
    Add your own custom tools or **MCP servers** to **access real-time information** or **execute actions** directly from your agents.
  </Card>
</Columns>

---

## Learning Journey

<Steps>
  <Step title="Video 1 — Uploading Documents and Basic Settings">
    <iframe src="https://www.loom.com/embed/71444a8e8f00462a9ffa1c30da310388" title="Loom video player" frameborder="0" className="w-full aspect-video rounded-xl" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen />

    **Objective of the use case:**\
    Learn how to configure a knowledge base and upload your first documents to feed an enterprise agent.

    **What you’ll see:**

    - Reviewing base settings: prompt, model, and creativity levels.
    - Adjusting **chunk size**, **overlap**, and **embedding configuration**.
    - Activating self-query and end-user query definitions for specific subjects.
    - Managing users and permissions within the workspace.
    - Uploading documents (example: “ticket guideline”) and tracking processing status.
    - Viewing extracted document content and validating ingestion success.
    - Asking domain-specific questions (e.g., “What are the steps for great ticket management?”).
    - Checking **sources** to confirm citation integrity.
    - Monitoring analytics for feedback, consumption, and token usage.

    **Result:**\
    Enterprise users can establish a governed knowledge base that enriches agent responses with traceable, document-backed information.
  </Step>
  <Step title="Video 2 — Advanced Settings, Tools, and Webhooks">
    <iframe src="https://www.loom.com/embed/4fcb121c1e8142c1b0022131dff09889" title="Loom video player" frameborder="0" className="w-full aspect-video rounded-xl" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen />

    **Objective of the use case:**\
    Discover how to use advanced configuration options, integrate external tools via MCP, and connect your workspace through APIs and webhooks.

    **What you’ll see:**

    - Adjusting **advanced options**: image generation, model filtering, compression, and clarification settings.
    - Enabling advanced features such as **Canvas**, **Code Interpreter**, and **Web Search**.
    - Adding external **MCP tools** (example: _DeepWiki_) and testing repository retrieval.
    - Understanding how tool descriptions help AI detect intent and execute the right functions.
    - Viewing tool usage directly in conversation sources.
    - Exploring **API and Webhook tabs**: retrieving project IDs and API keys for integration with AI Builder or enterprise systems.
    - Configuring webhook payloads for events like _document.created_, _question.asked_, or _document.updated_.
    - Managing additional **data sources** for hybrid retrieval.

    **Result:**\
    AI Knowledge becomes a fully extensible system, connecting external data and automation pipelines while maintaining strict governance and security.
  </Step>
  <Step title="Video 3 — Testing and Evaluation">
    <iframe src="https://www.loom.com/embed/ae5ed51bf5cc4639a5e3ab08668173b7" title="Loom video player" frameborder="0" className="w-full aspect-video rounded-xl" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen />

    **Objective of the use case:**\
    Learn how to validate and measure AI accuracy using the built-in testing and human evaluation features.

    **What you’ll see:**

    - Navigating to the **Testing Dashboard** via the sidebar.
    - Adding or importing test cases from Excel or other formats.
    - Creating a question (“What is an issue ticket?”) with a **reference answer**.
    - Running tests to evaluate AI responses against expected results.
    - Reviewing **answer score**, **context score**, and **reference comparison**.
    - Understanding **AI evaluation** metrics and detecting overperformance or gaps.
    - Acting as a **human-in-the-loop** evaluator: rating answers, context, and faithfulness manually.

    **Result:**\
    The testing feature allows enterprises to monitor AI response quality, measure relevance and faithfulness, and continuously improve their knowledge agents.
  </Step>
</Steps>

---

## Practical Applications

| Department         | Use Case                          | Description                                                                 |
| ------------------ | --------------------------------- | --------------------------------------------------------------------------- |
| Customer Support   | Knowledge Base Integration        | Build searchable, document-driven assistants for faster support resolution. |
| HR                 | Policy and Procedure Assistant    | Automate employee queries using verified internal documentation.            |
| IT / Operations    | Technical Documentation Retrieval | Connect engineers to updated, contextual technical content instantly.       |
| Legal & Compliance | Regulatory Knowledge Base         | Store and retrieve policies with traceable source verification.             |
| Quality Assurance  | AI Evaluation Framework           | Benchmark AI accuracy and maintain consistent response quality.             |

---

## Key Takeaways

- **Centralized RAG platform** for secure, compliant knowledge ingestion and retrieval.
- **Extensible integration layer** via tools, APIs, and webhooks.
- **Continuous improvement loop** through testing, analytics, and human evaluation.
- **Ideal for regulated industries** requiring precision, explainability, and auditability.