---
title: 'Configuring AI Knowledge'
description: 'Set up the AI Knowledge product for RAG (Retrieval-Augmented Generation) with model orchestration, rate limits, and vector stores.'
---

<Frame>
  <img src="/images/ai-knowledge-nav.png" alt="AI Knowledge Configuration" />
</Frame>

# Configuring AI Knowledge


**AI Knowledge** is Prisme.aiâ€™s product for agentic assistants powered by tools and **retrieval-augmented generation (RAG)**. It enables teams to build agents that leverage internal knowledge across various formats, interact with APIs via tools, and collaborate with other agents through context sharing â€” enabling true multi-agent workflows with robust LLM support and enterprise-grade configuration options.

This guide explains how to configure AI Knowledge in a **self-hosted** environment.

---

## Core Capabilities

- Configure multi-model support with failover and fine-tuned prompts
- Automate agent provisioning via AI Builder
- Enforce **limits**, **security**, and **monitoring**
- Enable **builtin tools** like summarization, search, code interpreter, web browsing
- Integrate with **OpenSearch**, **Redis**, or other vector stores

---

## Global Configuration Options

<AccordionGroup>

<Accordion title="Account Management">
- Disable account auto-creation to enforce user control:

```yaml
disableAccountCreation: true
```

Only existing users will be able to access shared agents.
</Accordion>

<Accordion title="Onboarding, Toasts & Statuses">
AI Knowledge supports onboarding flows, multilingual statuses, and customizable notifications:

```yaml
status:
  colors:
    published: '#5CA44A'
    pending: '#FF9261'
    draft: '#E5E5E5'
prompt:
  default: |
    You will only answer based on this context:
    ${context}
toasts:
  i18n:
    fr:
      documentCrawled: a Ã©tÃ© indexÃ© par votre IA ðŸ¤–
    en:
      documentCrawled: was indexed by your AI ðŸ¤–
```
</Accordion>

<Accordion title="Analytics Settings">
Use `analytics.useAggPayload: true` when working with OpenSearch to optimize event queries and data structure.
</Accordion>

<Accordion title="Model Defaults">
```yaml
defaultModels:
  completions: gpt-4o
  embeddings: az-embedding-ada
  enhanceQuery: gpt-3.5-turbo
  toolRouting: gpt-4o
```

Set base models for completions, embeddings, and query enhancement.
</Accordion>

<Accordion title="Model Specifications">
Configure all available models with descriptions, rate limits, and failover:

```yaml
modelsSpecifications:
  gpt-4o:
    maxContext: 128000
    pricing:
      input: 2.5
      output: 10
    rateLimits:
      tokensPerMinute: 100000
      requestsPerMinute: 1000
    failoverModel: gpt-3.5-turbo
    isHiddenFromEndUser: false
```

Set `isHiddenFromEndUser: true` to hide models in the UI.
</Accordion>

<Accordion title="Rate Limits">
Apply token and request limits globally or per user/project:

```yaml
limits:
  files_count: 20
  llm:
    users:
      tokensPerMinute: 100000
      requestsPerMinute: 20
    projects:
      tokensPerMinute: 30000
      requestsPerMinute: 300
  embeddings:
    projects:
      tokensPerMinute: 1000000
```
</Accordion>

<Accordion title="Model Aliases">
To manage naming across providers:

```yaml
modelAliases:
  gpt-4-azure: gpt-4
  gpt-4-openai: gpt-4
```

Use `gpt-4-azure` in your agent and map it back to the real name for provider APIs.
</Accordion>

<Accordion title="SSO Access">
To allow access to SSO users:

```yaml
auth:
  prismeai: {}
  mySSO: {}
```

Edit via workspace settings > Advanced > Edit Source Code.
</Accordion>

</AccordionGroup>

---

## Vector Store Configuration

To enable retrieval-based answers, configure a vector store:

```yaml
vectorStore:
  provider: redisSearch
  url: '{{secret.redisUrl}}'
```

Or with OpenSearch:

```yaml
vectorStore:
  provider: openSearch
  url: '{{secret.opensearchUrl}}'
  user: '{{secret.opensearchUser}}'
  password: '{{secret.opensearchPassword}}'
```

---

## Tools and Capabilities

AI Knowledge enables advanced agents via tools.

<CardGroup cols={2}>

<Card title="file_search" icon="magnifying-glass-chart">
RAG tool for semantic search within indexed documents.
</Card>

<Card title="file_summary" icon="scroll">
Summarize entire files when explicitly requested.
</Card>

<Card title="documents_rag" icon="book-open">
Used to extract context from project knowledge collections.
</Card>

<Card title="web_search" icon="globe">
Optional tool enabled via Serper API key:
```yaml
tools:
  webSearch:
    apiKey: '{{secret.serperApiKey}}'
```
</Card>

<Card title="code_interpreter" icon="code">
Python tool for data manipulation and document-based computation.
</Card>

<Card title="image_generation" icon="image">
Uses DALL-E or equivalant if enabled in LLM config.
</Card>

</CardGroup>

---

## Embedding Models

Embeddings are required for RAG indexing and similarity search.

```yaml
defaultModels.embeddings: az-embedding-ada
```

To change vector size or cost per provider, configure:

```yaml
modelsSpecifications:
  az-embedding-ada:
    type: embeddings
    maxContext: 2048
    pricing:
      input: 0.1
```

---

## Advanced Features

<AccordionGroup>

<Accordion title="AI Builder Automation">
AI Knowledge projects and agents can be provisioned programmatically via AI Builder workflows.
</Accordion>

<Accordion title="Multi-LLM & Region Routing">
You can configure multiple LLM backends (OpenAI, Azure, Bedrock, etc.):

```yaml
llm:
  openai:
    azure:
      resources:
        - resource: my-azure
          deployments:
            - az-gpt-4
```

Also supports OpenAI-compatible and Bedrock providers.
</Accordion>

<Accordion title="Failover Models">
Specify a backup model to switch to if the main one is overloaded:

```yaml
failoverModel: gpt-3.5-turbo
```

Make sure to enable failover in your workspace.
</Accordion>

<Accordion title="Token Management & Billing">
Assign costs per million tokens to track model usage:

```yaml
pricing:
  input: 2.5
  output: 10
```

This can be used with usage-based dashboards in AI Insights.
</Accordion>

</AccordionGroup>

---

## Next Steps

<CardGroup cols={2}>
  <Card
    title="SecureChat"
    icon="comment"
    href="/self-hosting/configuration/ai-securechat"
  >
    Create a ChatGPT-like agent within your organization â€” but secure, customizable, and connected to your tools and knowledge.
  </Card>
  <Card
    title="AI Builder"
    icon="wand-magic"
    href="/self-hosting/configuration/ai-builder"
  >
    Automate agent provisioning
  </Card>
  <Card
    title="Monitoring & Logs"
    icon="chart-column"
    href="/self-hosting/kubernetes/prometheus-grafana-operator"
  >
    Monitor usage and LLM activity
  </Card>
  <Card
    title="Create an agent"
    icon="wand-magic"
    href="/create-agents/overview"
  >
    Learn more about agent creation
  </Card>
</CardGroup>