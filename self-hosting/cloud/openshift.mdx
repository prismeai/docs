---
title: "Deploying Prisme.ai on OpenShift"
description: "Guide and best practices for deploying Prisme.ai in a self-hosted environment on OpenShift."
---

Red Hat OpenShift provides a robust Kubernetes-based platform ideal for enterprises deploying Prisme.ai. This guide covers key considerations, deployment steps, and best practices specifically tailored for OpenShift environments.

---

## OpenShift Prerequisites

Before starting deployment, ensure:

- You have a running **OpenShift cluster (version 4.12+)**.
- The **`OpenShift CLI (oc)`** is installed and configured.
- Administrator-level privileges for creating namespaces and resources.

---

## Recommended OpenShift Infrastructure

Deploy Prisme.ai utilizing OpenShift native resources and external services:

<AccordionGroup>
  <Accordion title="OpenShift Cluster Configuration">
    - **Recommended Cluster Resources**:
      - 3 master nodes (control plane), 3-5 worker nodes
      - Worker nodes: 4 vCPU / 16 GB RAM minimum per node
    - **Best Practices**:
      - Enable Cluster Autoscaler for optimal resource management.
      - Configure cluster for multi-zone or multi-region deployments for high availability.
  </Accordion>
  <Accordion title="Database (MongoDB / PostgreSQL)">
    - **Options**:
      - Self-hosted MongoDB on OpenShift via StatefulSets
      - Managed MongoDB services (e.g., MongoDB Atlas with VPC peering)
      - Or Self-hosted PostgreSQL on OpenShift
    - **Recommended Configuration**:
      - 3-node  replica set
    - **Best Practices**:
      - Persistent storage using OpenShift Storage Classes
      - Regular database backups via CronJobs
  </Accordion>
  <Accordion title="Search Engine (Elasticsearch/OpenSearch)">
    - **Options**:
      - Elasticsearch Operator for OpenShift
    - **Recommended Configuration**:
      - Elasticsearch Operator-managed cluster, minimum 3 nodes with 8GB RAM
    - **Best Practices**:
      - Utilize Persistent Volume Claims (PVC) for data durability
      - Regular backups with OpenShift backup strategies
  </Accordion>
  <Accordion title="Redis Cache">
    - **Options**:
      - Redis Operator for OpenShift
      - Managed Redis services
    - **Recommended Configuration**:
      - Redis cluster with 3 nodes for high availability
    - **Best Practices**:
      - Use PVC-backed storage
      - Integrate monitoring with Prometheus and Grafana Operators
  </Accordion>
  <Accordion title="Object Storage (S3-Compatible)">
    - **Options**:
      - External S3-compatible storage like MinIO or AWS S3
    - **Best Practices**:
      - Configure separate buckets for public assets, private uploads, and model storage
      - Enable lifecycle policies for efficient storage management
  </Accordion>
  <Accordion title="Persistent Storage (OpenShift Storage Classes)">
    - **Options**:
      - OpenShift Container Storage (OCS), NFS, Ceph RBD
    - **Recommended Configuration**:
      - Use storage classes supporting RWX for shared volumes (e.g., OCS)
    - **Best Practices**:
      - Schedule regular volume snapshots
      - Monitor storage performance using OpenShift’s monitoring stack
  </Accordion>
</AccordionGroup>

---

## OpenShift Deployment Steps

<Steps>
  <Step title="Create Project and Quotas">
    Create a dedicated project namespace and apply resource quotas:

    ```bash
    oc new-project prisme-ai
    oc apply -f resource-quota.yaml
    ```
  </Step>
  <Step title="Set up Operators and Databases">
    Install required Operators (Elasticsearch, Redis):

    - Navigate to OperatorHub in OpenShift Console, install Elasticsearch and Redis Operators.
    - Deploy MongoDB/PostgreSQL via StatefulSets or external services.
  </Step>
  <Step title="Deploy Object Storage Integration">
    Configure access to your chosen object storage (MinIO, AWS S3) using secrets and config maps:

    ```bash
    oc create secret generic s3-credentials \
      --from-literal=accesskey='your-access-key' \
      --from-literal=secretkey='your-secret-key'
    ```
  </Step>
  <Step title="Configure Routes and DNS">
    Set up OpenShift Routes for external access:

    - API: `api.yourdomain.com`
    - Console: `studio.yourdomain.com`
    - Pages: wildcard route `*.pages.yourdomain.com`
  </Step>
  <Step title="Deploy Prisme.ai via Helm">
    Use Helm 3 to deploy Prisme.ai:

    ```bash
    helm repo add prismeai https://helm.prisme.ai/charts
    helm install prisme-core prismeai/prismeai-core \
      --namespace prisme-ai -f values.yaml
    ```

    Ensure `values.yaml` reflects your environment settings.
  </Step>
  <Step title="Ingress & SSL with OpenShift Routes">
    Configure TLS certificates and termination via OpenShift routes:

    ```bash
    oc create route edge prisme-api --service=api-service --hostname=api.yourdomain.com
    ```
  </Step>
</Steps>

---

## Security Best Practices

<CardGroup cols={2}>
  <Card title="RBAC & Project Isolation" icon="shield-halved">
    - Utilize OpenShift’s built-in RBAC to enforce role-based permissions.
    - Ensure clear separation between different Prisme.ai environments.
  </Card>
  <Card title="Network Policies" icon="network-wired">
    - Implement strict network policies for inter-service communication.
    - Utilize OpenShift SDN for advanced network security.
  </Card>
  <Card title="Secrets Management" icon="key">
    - Securely manage sensitive configurations using OpenShift Secrets.
    - Regularly rotate and audit secrets usage.
  </Card>
  <Card title="Integrated Monitoring" icon="eye">
    - Leverage OpenShift’s integrated Prometheus and Grafana for proactive monitoring.
    - Configure alerts and dashboards tailored to Prisme.ai workloads.
  </Card>
</CardGroup>

---

## Next Steps

<CardGroup cols={2}>
  <Card title="Helm Deployment" icon="ship" href="/self-hosting/kubernetes/helm">
    Deploy Prisme.ai using Helm
  </Card>
  <Card title="Products Configuration" icon="store" href="/self-hosting/configuration/ai-store">
    Configure your Prisme.ai AI products
  </Card>
  <Card title="Operations Management" icon="scale-unbalanced" href="/self-hosting/operations/scaling">
    Learn about scaling operations efficiently
  </Card>
</CardGroup>