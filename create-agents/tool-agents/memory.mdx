---
title: 'Memory Management'
description: 'Learn how to implement effective memory and state management for tool-using agents to maintain context across interactions'
---

Effective memory management enables tool-using agents to maintain context, remember previous interactions, and execute multi-step processes. This guide explores strategies and techniques for implementing robust memory systems in Prisme.ai agents.


## Understanding Agent Memory

Memory in tool-using agents refers to the agent's ability to:

1. **Retain information** from previous interactions
2. **Maintain state** during multi-step processes
3. **Access historical context** to inform current decisions
4. **Track tool usage** results for continuity
5. **Persist user preferences** and settings

<Note>
  Effective memory management creates a coherent, continuous experience across multiple interactions, enabling complex workflows that span multiple turns of conversation.
</Note>

## Types of Agent Memory

Tool-using agents typically require several types of memory:

<CardGroup cols={2}>
  <Card title="Conversation Memory" icon="comments">
    Recent interaction history between user and agent
    
    **Used for**:
    - Maintaining conversation coherence
    - Understanding references to previous mentions
    - Contextualizing new requests
    - Providing consistent responses
  </Card>
  
  <Card title="Tool State Memory" icon="tools">
    Results and context from previous tool usage
    
    **Used for**:
    - Referring to previous tool results
    - Continuing multi-step tool processes
    - Building on previous operations
    - Avoiding redundant tool executions
  </Card>
  
  <Card title="User Profile Memory" icon="user">
    Persistent information about the specific user
    
    **Used for**:
    - Personalizing responses
    - Remembering preferences
    - Adapting to user expertise levels
    - Maintaining user-specific settings
  </Card>
  
  <Card title="Process Memory" icon="diagram-project">
    State information for ongoing workflows
    
    **Used for**:
    - Tracking progress in multi-step processes
    - Maintaining form completion state
    - Managing approval workflows
    - Tracking decision points and branches
  </Card>
</CardGroup>

## Memory Challenges in Tool-Using Agents

Implementing effective memory in tool-using agents presents several unique challenges:

<CardGroup cols={2}>
  <Card title="Scale and Storage" icon="database">
    Managing potentially large volumes of interaction data
  </Card>
  <Card title="Relevance Filtering" icon="filter">
    Identifying which information is relevant to the current interaction
  </Card>
  <Card title="Context Limits" icon="brackets-curly">
    Working within the constraints of LLM context windows
  </Card>
  <Card title="State Synchronization" icon="arrows-rotate">
    Maintaining consistent state across distributed components
  </Card>
  <Card title="Privacy and Security" icon="shield-halved">
    Protecting sensitive information in memory systems
  </Card>
  <Card title="Memory Decay" icon="hourglass-half">
    Implementing appropriate forgetting mechanisms
  </Card>
</CardGroup>

## Memory Implementation in Prisme.ai

Prisme.ai provides several mechanisms for implementing memory in tool-using agents:

<Tabs>
  <Tab title="LLM Context Window">
    Use the model's context window for short-term memory.
    
    **How it works**:
    - Recent conversation history is included in prompts
    - The LLM maintains continuity based on this history
    - Tool results are appended to the conversation
    - The context window serves as working memory
    
    **Best for**:
    - Short-term memory needs
    - Simple conversation continuity
    - Limited interaction complexity
    - Minimal state requirements
    
    **Limitations**:
    - Bounded by context window size
    - Limited persistence
    - No structured state management
    - Potential for information loss as history grows
  </Tab>
  
  <Tab title="Conversation State">
    Maintain structured state in conversation sessions.
    
    **How it works**:
    - Dedicated state object persists throughout a conversation
    - State is updated with each interaction
    - Structured data can be stored and retrieved
    - State informs tool selection and execution
    
    **Best for**:
    - Single-session interactions
    - Tracking progress within a conversation
    - Maintaining conversation-specific context
    - Session-level user preferences
    
    **Limitations**:
    - Typically limited to current session
    - May have storage constraints
    - Usually scoped to one conversation
  </Tab>
  
  <Tab title="Database Persistence">
    Store information in databases for long-term memory.
    
    **How it works**:
    - Information is stored in structured databases
    - Persistent across sessions and conversations
    - Queryable with specific retrieval patterns
    - Can store large volumes of historical data
    
    **Best for**:
    - Long-term user profiles
    - Cross-session continuity
    - Complex state management
    - Structured information storage
    
    **Limitations**:
    - Higher implementation complexity
    - Potential performance impacts
    - Requires careful schema design
    - Security and privacy considerations
  </Tab>
  
  <Tab title="Event History">
    Use Prisme.ai's event system for memory through events.
    
    **How it works**:
    - Events are logged during agent interactions
    - Event history can be queried for context
    - Event data includes tool usage, results, and user inputs
    - Activity logs provide a comprehensive record
    
    **Best for**:
    - Debugging and troubleshooting
    - Audit trails and compliance
    - Analyzing interaction patterns
    - Technical diagnostics
    
    **Limitations**:
    - Not optimized for real-time lookups
    - Primarily designed for technical users
    - Can contain excess information
    - May require filtering for relevance
  </Tab>
</Tabs>

## Implementing Conversation Memory

For most agents, conversation memory is the foundation of context management:

<Steps>
  <Step title="Configure Memory Storage">
    Set up appropriate storage for conversation history.
    
    In AI Knowledge, configure:
    - Conversation history retention
    - Message count limitations
    - Storage location (default or custom)
    
    In AI Builder, implement:
    ```yaml
    slug: conversation-memory-setup
    do:
      - DB.createTable:
          name: conversation_memory
          schema:
            conversationId: string
            timestamp: timestamp
            messageHistory: array
            state: object
      - emit:
          event: memory.initialized
          data:
            status: success
    ```
  </Step>
  
  <Step title="Create Memory Management Functions">
    Implement functions to save and retrieve memory data.
    
    Example implementation:
    ```yaml
    slug: memory-manager
    do:
      - conditions:
          '{{event.type}} == "memory.store"':
            - DB.upsert:
                table: conversation_memory
                key:
                  conversationId: '{{event.data.conversationId}}'
                values:
                  timestamp: '{{now()}}'
                  messageHistory: '{{event.data.messageHistory}}'
                  state: '{{event.data.state}}'
            - emit:
                event: memory.stored
                data:
                  conversationId: '{{event.data.conversationId}}'
          '{{event.type}} == "memory.retrieve"':
            - DB.get:
                table: conversation_memory
                key:
                  conversationId: '{{event.data.conversationId}}'
                output: memoryData
            - emit:
                event: memory.retrieved
                data:
                  conversationId: '{{event.data.conversationId}}'
                  memory: '{{memoryData}}'
    ```
  </Step>
  
  <Step title="Implement Memory Updates">
    Update memory during agent interactions.
    
    Example update logic:
    ```yaml
    slug: update-conversation-memory
    do:
      # Get existing memory
      - DB.get:
          table: conversation_memory
          key:
            conversationId: '{{event.data.conversationId}}'
          output: existingMemory
      # Prepare updated memory
      - set:
          name: updatedHistory
          value: '{% if existingMemory.messageHistory %}{{existingMemory.messageHistory}}{% else %}[]{% endif %}'
      - set:
          name: updatedHistory
          value: '{% append(updatedHistory, {"role": event.data.message.role, "content": event.data.message.content, "timestamp": now()}) %}'
      # Trim history if needed
      - conditions:
          '{{length(updatedHistory)}} > {{config.maxHistoryMessages}}':
            - set:
                name: updatedHistory
                value: '{% slice(updatedHistory, length(updatedHistory) - config.maxHistoryMessages, length(updatedHistory)) %}'
      # Update state if provided
      - set:
          name: updatedState
          value: '{% if event.data.stateUpdates %}{% merge(existingMemory.state || {}, event.data.stateUpdates) %}{% else %}{{existingMemory.state || {}}}{% endif %}'
      # Store updated memory
      - DB.upsert:
          table: conversation_memory
          key:
            conversationId: '{{event.data.conversationId}}'
          values:
            timestamp: '{{now()}}'
            messageHistory: '{{updatedHistory}}'
            state: '{{updatedState}}'
      - emit:
          event: memory.updated
          data:
            conversationId: '{{event.data.conversationId}}'
    ```
  </Step>
  
  <Step title="Integrate Memory with LLM Context">
    Format memory for inclusion in LLM prompts.
    
    Example implementation:
    ```yaml
    slug: prepare-llm-context
    do:
      # Retrieve memory
      - DB.get:
          table: conversation_memory
          key:
            conversationId: '{{event.data.conversationId}}'
          output: memory
      # Format conversation history
      - set:
          name: formattedHistory
          value: ''
      - repeat:
          array: '{{memory.messageHistory || []}}'
          item: message
          do:
            - set:
                name: formattedHistory
                value: '{{formattedHistory}}{{message.role}}: {{message.content}}\n\n'
      # Prepare tool context if applicable
      - set:
          name: toolContext
          value: ''
      - conditions:
          '{{memory.state.lastToolResult}}':
            - set:
                name: toolContext
                value: 'Previous tool result: {{memory.state.lastToolResult}}\n\n'
      # Combine contexts
      - set:
          name: fullContext
          value: '{{toolContext}}{{formattedHistory}}'
      - emit:
          event: llm.context.prepared
          data:
            conversationId: '{{event.data.conversationId}}'
            context: '{{fullContext}}'
            state: '{{memory.state || {}}}'
    ```
  </Step>
  
  <Step title="Implement Memory Cleanup">
    Create mechanisms for appropriate memory management.
    
    
    Example implementation:
    ```yaml
    slug: memory-cleanup
    do:
      # Clean up old conversations
      - DB.delete:
          table: conversation_memory
          filter:
            timestamp: {lt: '{% date.add(now(), -30, "days") %}'}
      # Emit cleanup event
      - emit:
          event: memory.cleanup.completed
          data:
            timestamp: '{{now()}}'
    ```
  </Step>
</Steps>

## Implementing Tool State Memory

Tool-using agents require specialized memory for tool results and context:

<Accordion title="Tool Result Storage">
  Store the results of tool executions for future reference.
  
  **Example implementation**:
  ```yaml
  slug: store-tool-result
  do:
    # Get existing memory
    - DB.get:
        table: conversation_memory
        key:
          conversationId: '{{event.data.conversationId}}'
        output: memory
    # Initialize or update tool results collection
    - set:
        name: toolResults
        value: '{% if memory.state.toolResults %}{{memory.state.toolResults}}{% else %}{}{% endif %}'
    # Add new tool result
    - set:
        name: toolResults[event.data.toolName]
        value:
          result: '{{event.data.result}}'
          timestamp: '{{now()}}'
          parameters: '{{event.data.parameters}}'
    # Update memory with tool results
    - DB.upsert:
        table: conversation_memory
        key:
          conversationId: '{{event.data.conversationId}}'
        values:
          timestamp: '{{now()}}'
          state.toolResults: '{{toolResults}}'
          state.lastToolUsed: '{{event.data.toolName}}'
          state.lastToolResult: '{{event.data.result}}'
    # Emit event
    - emit:
        event: tool.result.stored
        data:
          conversationId: '{{event.data.conversationId}}'
          toolName: '{{event.data.toolName}}'
  ```
  
  This implementation:
  - Stores detailed tool execution information
  - Maintains a history of tool usage
  - Tracks the most recent tool result
  - Preserves parameter information for context
</Accordion>

<Accordion title="Tool Context Preparation">
  Format tool-specific context for LLM prompts.
  
  **Example implementation**:
  ```yaml
  slug: prepare-tool-context
  do:
    # Retrieve memory
    - DB.get:
        table: conversation_memory
        key:
          conversationId: '{{event.data.conversationId}}'
        output: memory
    # Check for tool history
    - conditions:
        '{{memory.state.toolResults}}':
          # Format recent tool usage
          - set:
              name: toolContext
              value: "Recent tool usage:\n\n"
          - repeat:
              array: '{% Object.keys(memory.state.toolResults).slice(-3) %}'  # Last 3 tools used
              item: toolName
              do:
                - set:
                    name: toolInfo
                    value: '{{memory.state.toolResults[toolName]}}'
                - set:
                    name: toolContext
                    value: '{{toolContext}}Tool: {{toolName}}\nUsed at: {{toolInfo.timestamp}}\nResult: {{toolInfo.result}}\n\n'
          # Add specific context for current request if continuing from previous tool
          - conditions:
              '{{event.data.relatedToTool}} && {{memory.state.toolResults[event.data.relatedToTool]}}':
                - set:
                    name: relevantToolResult
                    value: '{{memory.state.toolResults[event.data.relatedToTool]}}'
                - set:
                    name: toolContext
                    value: '{{toolContext}}For your current request, this information from a previous {{event.data.relatedToTool}} operation is relevant:\n{{relevantToolResult.result}}\n\n'
        'else':
          - set:
              name: toolContext
              value: ''
    # Return prepared context
    - emit:
        event: tool.context.prepared
        data:
          conversationId: '{{event.data.conversationId}}'
          toolContext: '{{toolContext}}'
  ```
  
  This implementation:
  - Creates a summary of recent tool usage
  - Highlights tool results relevant to the current query
  - Formats the information for LLM consumption
  - Provides continuity across tool interactions
</Accordion>

<Accordion title="Multi-Step Tool Processes">
  Maintain state for tools that require multiple steps.
  
  **Example implementation**:
  ```yaml
  slug: multi-step-tool-state
  do:
    # Get existing memory
    - DB.get:
        table: conversation_memory
        key:
          conversationId: '{{event.data.conversationId}}'
        output: memory
    # Check if there's an active process
    - conditions:
        '{{event.data.action}} == "start" && {{event.data.processType}}':
          # Initialize new process
          - set:
              name: processState
              value:
                processType: '{{event.data.processType}}'
                startedAt: '{{now()}}'
                currentStep: 1
                totalSteps: '{{event.data.totalSteps}}'
                data: '{{event.data.initialData || {}}}'
                status: 'in_progress'
          - DB.upsert:
              table: conversation_memory
              key:
                conversationId: '{{event.data.conversationId}}'
              values:
                state.activeProcess: '{{processState}}'
        '{{event.data.action}} == "update" && {{memory.state.activeProcess}}':
          # Update existing process
          - set:
              name: updatedProcess
              value: '{{memory.state.activeProcess}}'
          - set:
              name: updatedProcess.currentStep
              value: '{% if event.data.step %}{{event.data.step}}{% else %}{{memory.state.activeProcess.currentStep + 1}}{% endif %}'
          - set:
              name: updatedProcess.data
              value: '{% merge(memory.state.activeProcess.data, event.data.data || {}) %}'
          - set:
              name: updatedProcess.lastUpdated
              value: '{{now()}}'
          - DB.upsert:
              table: conversation_memory
              key:
                conversationId: '{{event.data.conversationId}}'
              values:
                state.activeProcess: '{{updatedProcess}}'
        '{{event.data.action}} == "complete" && {{memory.state.activeProcess}}':
          # Complete the process
          - set:
              name: completedProcess
              value: '{{memory.state.activeProcess}}'
          - set:
              name: completedProcess.status
              value: 'completed'
          - set:
              name: completedProcess.completedAt
              value: '{{now()}}'
          - DB.upsert:
              table: conversation_memory
              key:
                conversationId: '{{event.data.conversationId}}'
              values:
                state.activeProcess: null
                state.completedProcesses: '{% append(memory.state.completedProcesses || [], completedProcess) %}'
        '{{event.data.action}} == "cancel" && {{memory.state.activeProcess}}':
          # Cancel the process
          - set:
              name: canceledProcess
              value: '{{memory.state.activeProcess}}'
          - set:
              name: canceledProcess.status
              value: 'canceled'
          - set:
              name: canceledProcess.canceledAt
              value: '{{now()}}'
          - DB.upsert:
              table: conversation_memory
              key:
                conversationId: '{{event.data.conversationId}}'
              values:
                state.activeProcess: null
                state.canceledProcesses: '{% append(memory.state.canceledProcesses || [], canceledProcess) %}'
    # Emit event
    - emit:
        event: process.state.updated
        data:
          conversationId: '{{event.data.conversationId}}'
          action: '{{event.data.action}}'
  ```
  
  This implementation:
  - Manages multi-step processes with defined workflows
  - Tracks progress through steps
  - Maintains process-specific data
  - Handles process completion and cancellation
</Accordion>

## Implementing User Profile Memory

For personalized agent experiences, implement persistent user profiles:

<Steps>
  <Step title="Create User Profile Structure">
    Define the schema for user profile information.
    
    
    Example schema:
    ```yaml
    userProfileSchema:
      type: object
      properties:
        userId:
          type: string
        preferences:
          type: object
          properties:
            language:
              type: string
            notificationPreferences:
              type: object
            displayPreferences:
              type: object
        expertise:
          type: object
          properties:
            technicalLevel:
              type: string
              enum: [beginner, intermediate, advanced]
            domainExpertise:
              type: array
              items:
                type: string
        history:
          type: object
          properties:
            frequentTools:
              type: array
            recentSearches:
              type: array
            savedItems:
              type: array
    ```
  </Step>
  
  <Step title="Implement Profile Management">
    Create mechanisms to create, retrieve, and update profiles.
    
    Example implementation:
    ```yaml
    slug: user-profile-manager
    do:
      - conditions:
          '{{event.type}} == "profile.get"':
            - DB.get:
                table: user_profiles
                key:
                  userId: '{{event.data.userId}}'
                output: userProfile
            - emit:
                event: profile.retrieved
                data:
                  userId: '{{event.data.userId}}'
                  profile: '{{userProfile || {}}}'
          '{{event.type}} == "profile.update"':
            - DB.get:
                table: user_profiles
                key:
                  userId: '{{event.data.userId}}'
                output: existingProfile
            - set:
                name: updatedProfile
                value: '{% merge(existingProfile || {}, event.data.updates) %}'
            - DB.upsert:
                table: user_profiles
                key:
                  userId: '{{event.data.userId}}'
                values: '{{updatedProfile}}'
            - emit:
                event: profile.updated
                data:
                  userId: '{{event.data.userId}}'
                  profile: '{{updatedProfile}}'
    ```
  </Step>
  
  <Step title="Integrate Profiles with Agent Behavior">
    Use profile information to personalize agent responses.
    
    Example implementation:
    ```yaml
    slug: personalized-agent-response
    do:
      # Get user profile
      - DB.get:
          table: user_profiles
          key:
            userId: '{{event.data.userId}}'
          output: userProfile
      # Get conversation memory
      - DB.get:
          table: conversation_memory
          key:
            conversationId: '{{event.data.conversationId}}'
          output: conversationMemory
      # Prepare personalization instructions
      - set:
          name: personalizationContext
          value: ''
      # Add expertise-based personalization
      - conditions:
          '{{userProfile.expertise.technicalLevel}}':
            - set:
                name: personalizationContext
                value: '{{personalizationContext}}The user has a {{userProfile.expertise.technicalLevel}} technical level. {% if userProfile.expertise.technicalLevel == "advanced" %}You can use technical terminology and provide detailed explanations.{% elif userProfile.expertise.technicalLevel == "beginner" %}Avoid technical jargon and provide simple explanations.{% endif %}\n\n'
      # Add language preference
      - conditions:
          '{{userProfile.preferences.language}}':
            - set:
                name: personalizationContext
                value: '{{personalizationContext}}The user prefers communications in {{userProfile.preferences.language}}.\n\n'
      # Add domain expertise
      - conditions:
          '{{userProfile.expertise.domainExpertise}}':
            - set:
                name: personalizationContext
                value: '{{personalizationContext}}The user has expertise in: {{userProfile.expertise.domainExpertise.join(", ")}}.\n\n'
      # Add frequently used tools
      - conditions:
          '{{userProfile.history.frequentTools}}':
            - set:
                name: personalizationContext
                value: '{{personalizationContext}}Tools the user frequently uses: {{userProfile.history.frequentTools.join(", ")}}.\n\n'
      # Emit prepared context
      - emit:
          event: personalization.context.prepared
          data:
            conversationId: '{{event.data.conversationId}}'
            userId: '{{event.data.userId}}'
            personalizationContext: '{{personalizationContext}}'
    ```
  </Step>
  
  <Step title="Update Profiles Based on Interactions">
    Continuously refine user profiles based on agent interactions.
    
    
    Example implementation:
    ```yaml
    slug: profile-learning
    do:
      # When a tool is used, update frequentTools
      - conditions:
          '{{event.type}} == "tool.executed"':
            - DB.get:
                table: user_profiles
                key:
                  userId: '{{event.data.userId}}'
                output: userProfile
            # Initialize if needed
            - set:
                name: toolUsage
                value: '{% if userProfile.history && userProfile.history.frequentTools %}{{userProfile.history.frequentTools}}{% else %}[]{% endif %}'
            # Add current tool
            - set:
                name: toolUsage
                value: '{% append(toolUsage, event.data.toolName) %}'
            # Keep only the most recent 20 tools
            - conditions:
                '{{length(toolUsage)}} > 20':
                  - set:
                      name: toolUsage
                      value: '{% slice(toolUsage, length(toolUsage) - 20, length(toolUsage)) %}'
            # Count frequency
            - set:
                name: toolCounts
                value: '{}'
            - repeat:
                array: '{{toolUsage}}'
                item: tool
                do:
                  - set:
                      name: toolCounts[tool]
                      value: '{% if toolCounts[tool] %}{{toolCounts[tool] + 1}}{% else %}1{% endif %}'
            # Get top 5 most frequent
            - set:
                name: frequentTools
                value: '{% Object.entries(toolCounts).sort((a, b) => b[1] - a[1]).slice(0, 5).map(entry => entry[0]) %}'
            # Update profile
            - DB.upsert:
                table: user_profiles
                key:
                  userId: '{{event.data.userId}}'
                values:
                  history.toolUsage: '{{toolUsage}}'
                  history.frequentTools: '{{frequentTools}}'
            - emit:
                event: profile.tools.updated
                data:
                  userId: '{{event.data.userId}}'
      # Similar handlers for other interaction types
    ```
  </Step>
</Steps>

## Advanced Memory Techniques

For sophisticated agent experiences, consider these advanced memory approaches:

<Accordion title="Semantic Memory Retrieval">
  Use embeddings to retrieve relevant historical information.
  
  **Example implementation**:
  ```yaml
  slug: semantic-memory-retrieval
  do:
    # Get user query
    - set:
        name: query
        value: '{{event.data.query}}'
    # Generate embedding for query
    - AI.generateEmbedding:
        text: '{{query}}'
        output: queryEmbedding
    # Retrieve conversation history
    - DB.get:
        table: conversation_memory
        key:
          conversationId: '{{event.data.conversationId}}'
        output: conversationMemory
    # Generate embeddings for history if not already present
    - conditions:
        '{{!conversationMemory.messageEmbeddings}}':
          - set:
              name: messageEmbeddings
              value: {}
          - repeat:
              array: '{{conversationMemory.messageHistory || []}}'
              item: message
              index: i
              do:
                - AI.generateEmbedding:
                    text: '{{message.content}}'
                    output: messageEmbedding
                - set:
                    name: messageEmbeddings[i]
                    value: '{{messageEmbedding}}'
          - DB.upsert:
              table: conversation_memory
              key:
                conversationId: '{{event.data.conversationId}}'
              values:
                messageEmbeddings: '{{messageEmbeddings}}'
        'else':
          - set:
              name: messageEmbeddings
              value: '{{conversationMemory.messageEmbeddings}}'
    # Calculate similarity scores
    - set:
        name: similarities
        value: []
    - repeat:
        array: '{{Object.keys(messageEmbeddings)}}'
        item: index
        do:
          - set:
              name: similarity
              value: '{% calculateCosineSimilarity(queryEmbedding, messageEmbeddings[index]) %}'
          - set:
              name: similarities
              value: '{% append(similarities, {"index": parseInt(index), "score": similarity}) %}'
    # Sort by similarity and get top results
    - set:
        name: topResults
        value: '{% similarities.sort((a, b) => b.score - a.score).slice(0, 5) %}'
    # Extract relevant messages
    - set:
        name: relevantHistory
        value: []
    - repeat:
        array: '{{topResults}}'
        item: result
        do:
          - set:
              name: relevantMessage
              value: '{{conversationMemory.messageHistory[result.index]}}'
          - set:
              name: relevantHistory
              value: '{% append(relevantHistory, {"content": relevantMessage.content, "role": relevantMessage.role, "similarity": result.score}) %}'
    # Return relevant history
    - emit:
        event: memory.relevant.retrieved
        data:
          conversationId: '{{event.data.conversationId}}'
          query: '{{query}}'
          relevantHistory: '{{relevantHistory}}'
  ```
  
  This technique:
  - Uses embeddings to find semantically relevant conversation history
  - Prioritizes relevant context regardless of recency
  - Optimizes context window usage
  - Surfaces important historical information
</Accordion>

<Accordion title="Hierarchical Memory Organization">
  Organize memory at multiple levels of persistence and accessibility.
  
  **Implementation approach**:
  ```
  Memory Tiers:
  
  1. Working Memory (Context Window)
     - Most recent messages
     - Current tool results
     - Immediate context for the ongoing interaction
  
  2. Session Memory (Conversation State)
     - Complete conversation history
     - All tool results from the current session
     - Active workflows and their state
  
  3. User Memory (Profile)
     - Preferences and settings
     - Expertise levels and interests
     - Usage patterns and history
  
  4. Collective Memory (Knowledge Base)
     - Common patterns across users
     - Frequently asked questions
     - Standard workflows and processes
  ```
  
  This approach:
  - Ensures appropriate information availability at each level
  - Optimizes storage and retrieval efficiency
  - Scales from immediate context to organizational knowledge
  - Provides appropriate persistence for different information types
</Accordion>

<Accordion title="Memory Summarization">
  Create and maintain summaries of conversation history.
  
  **Example implementation**:
  ```yaml
  slug: conversation-summarizer
  do:
    # Retrieve recent conversation history
    - DB.get:
        table: conversation_memory
        key:
          conversationId: '{{event.data.conversationId}}'
        output: memory
    # Check if we need a new summary
    - conditions:
        '{{!memory.state.conversationSummary || memory.messageHistory.length - memory.state.lastSummarizedMessage > 10}}':
          # Prepare messages for summarization
          - set:
              name: messagesToSummarize
              value: '{% if memory.state.lastSummarizedMessage %}{{memory.messageHistory.slice(memory.state.lastSummarizedMessage)}}{% else %}{{memory.messageHistory}}{% endif %}'
          # Format for summarization
          - set:
              name: conversationText
              value: ''
          - repeat:
              array: '{{messagesToSummarize}}'
              item: message
              do:
                - set:
                    name: conversationText
                    value: '{{conversationText}}{{message.role}}: {{message.content}}\n\n'
          # Generate or update summary
          - conditions:
              '{{memory.state.conversationSummary}}':
                # Update existing summary
                - LLM.generate:
                    prompt: 'You are summarizing an ongoing conversation. Here is the current summary:\n\n{{memory.state.conversationSummary}}\n\nHere are new messages to incorporate:\n\n{{conversationText}}\n\nPlease provide an updated summary that covers the entire conversation, focusing on key points, decisions, and context that would be important for future reference.'
                    output: newSummary
              'else':
                # Create new summary
                - LLM.generate:
                    prompt: 'Please summarize this conversation, focusing on key points, decisions, and context that would be important for future reference:\n\n{{conversationText}}'
                    output: newSummary
          # Store the updated summary
          - DB.upsert:
              table: conversation_memory
              key:
                conversationId: '{{event.data.conversationId}}'
              values:
                state.conversationSummary: '{{newSummary}}'
                state.lastSummarizedMessage: '{{memory.messageHistory.length}}'
          - emit:
              event: conversation.summarized
              data:
                conversationId: '{{event.data.conversationId}}'
                summary: '{{newSummary}}'
    # Return existing summary if available
    - conditions:
        '{{memory.state.conversationSummary}}':
          - emit:
              event: conversation.summary.retrieved
              data:
                conversationId: '{{event.data.conversationId}}'
                summary: '{{memory.state.conversationSummary}}'
  ```
  
  This technique:
  - Creates concise summaries of conversation history
  - Updates summaries incrementally as conversations progress
  - Reduces context window requirements for long conversations
  - Preserves essential information while managing token usage
</Accordion>

## Best Practices for Memory Management

<CardGroup cols={2}>
  <Card title="Right-Size Memory Storage" icon="database">
    Match memory persistence to information importance:
    
    - Short-term context: Keep in context window
    - Session state: Store in conversation memory
    - User information: Maintain in persistent profiles
    - Configuration data: Store in system settings
  </Card>
  
  <Card title="Implement Memory Privacy" icon="shield-halved">
    Protect sensitive information in memory systems:
    
    - Implement appropriate data retention policies
    - Provide clear mechanisms for users to clear history
    - Avoid storing unnecessary sensitive information
    - Apply proper access controls to memory stores
  </Card>
  
  <Card title="Optimize Context Selection" icon="filter">
    Be selective about what goes into the LLM context:
    
    - Prioritize recent and relevant messages
    - Include tool results that inform current queries
    - Add active workflow state for ongoing processes
    - Consider user expertise level and preferences
  </Card>
  
  <Card title="Implement Intelligent Forgetting" icon="trash">
    Design appropriate memory decay mechanisms:
    
    - Archive or summarize older conversations
    - Gradually reduce detail level of historical information
    - Implement tiered storage with different retention periods
    - Provide explicit forgetting capabilities when appropriate
  </Card>
</CardGroup>

## Memory Management in AI Knowledge

For AI Knowledge agents, configure memory effectively through these approaches:

<Steps>
  <Step title="Configure Conversation History">
    Set appropriate history retention in AI Knowledge.
  
    
    Key settings include:
    - Message retention count
    - Context window utilization
    - Token budget allocation
    - History formatting preferences
  </Step>
  
  <Step title="Define Memory Instructions">
    Add specific memory-related guidance in agent instructions.
    
    
    Example instructions:
    ```
    Memory Usage Guidelines:
    
    1. Maintain continuity by referencing previous parts of our conversation when relevant
    
    2. If the user refers to something mentioned earlier, acknowledge that you remember it
    
    3. For multi-step processes, keep track of what steps have been completed and what remains
    
    4. When using tools multiple times, remember previous tool results if they remain relevant
    
    5. If you need information that was previously discussed but may no longer be in context, politely ask the user to confirm or repeat it
    ```
  </Step>
  
  <Step title="Configure Tool Memory">
    Set up how tool results are stored and referenced.
    
    Key configuration elements:
    - Tool result retention settings
    - Result format in conversation history
    - Integration with subsequent prompts
    - Tool state persistence options
  </Step>
  
  <Step title="Test Memory Effectiveness">
    Verify memory management with multi-turn scenarios.
    
    Testing should include:
    - References to previous information
    - Multi-step processes spanning several turns
    - Tool usage with result referencing
    - Edge cases like very long conversations
  </Step>
</Steps>

## Next Steps

Ready to implement effective memory management for your agents? Continue with these resources:

<CardGroup cols={2}>
  <Card title="Execution & Activity" icon="bolt" href="/create-agents/tool-agents/execution-activity">
    Learn how to monitor and debug tool execution
  </Card>
  <Card title="Error Handling" icon="triangle-exclamation" href="/create-agents/tool-agents/error-handling">
    Implement robust error management for tools
  </Card>
  <Card title="Multi-Agent Systems" icon="users" href="/create-agents/multi-agents/overview">
    Explore memory in collaborative agent systems
  </Card>
  <Card title="Advanced RAG" icon="wand-sparkles" href="/create-agents/rag-agents/advanced-rag">
    Discover memory techniques for knowledge agents
  </Card>
</CardGroup>